{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7d6147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import EarlyStoppingCallback\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17831610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                     text       label\n",
      "0      Sou aluna de doutorado da UFPR e pesquiso sobr...    academic\n",
      "1      Gostaria de consultar a disponibilidade de c√≥d...    academic\n",
      "2      Prezados, bom dia. Procurei no site do Serpro ...  government\n",
      "3      Solicito o n√∫mero de matr√≠cula do SIAP do doce...    academic\n",
      "4      A Lei n¬∫ 12772/2012 regulamenta a carreira de ...    academic\n",
      "...                                                  ...         ...\n",
      "43673  Bom dia. gostaria de saber qual √© o procedimen...     private\n",
      "43674  Gostaria de saber se a Institui√ß√£o possui comi...  government\n",
      "43675  Gostaria de obter informa√ß√£o sobre o registro ...    academic\n",
      "43676  Ao Ilmo. membro do Instituto Nacional do Segur...    academic\n",
      "43677  Contrato CRT/DF 31.200/2012, aditivos, notas t...     private\n",
      "\n",
      "[43678 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/content/drive/MyDrive/PLN/EP2/ep2-train.csv\"\n",
    "df = pd.read_csv('./data/ep2-train.csv',\n",
    "  encoding=\"ISO-8859-1\",\n",
    "  sep=\";\",\n",
    "  decimal=\",\",)\n",
    "df.columns = [\"text\", \"label\"]\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c78553c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_column = df.loc[:,'text'].str.lower()\n",
    "text_column = text_column.values # ou to_numpy() ‚Äì veja documenta√ß√£o pandas\n",
    "vect = TfidfVectorizer(ngram_range=(1,1),analyzer='word')\n",
    "X = vect.fit_transform(df['text']) # para uso posterior, na classifica√ß√£o\n",
    "meuAnalyzer = vect.build_analyzer()\n",
    "tokenList = []\n",
    "for item in text_column:\n",
    "  tokens = meuAnalyzer(item)\n",
    "  tokenList.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbe02ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Carregando modelo Word2Vec existente...\n"
     ]
    }
   ],
   "source": [
    "tamanho = 300\n",
    "janela = 1\n",
    "minimoC = 1\n",
    "caminho_modelo = \"./models/word2vec/\"+str(tamanho)+\".kv\"\n",
    "\n",
    "# cria pasta se n√£o existir\n",
    "os.makedirs(os.path.dirname(caminho_modelo), exist_ok=True)\n",
    "\n",
    "# verifica se o modelo existe\n",
    "if os.path.exists(caminho_modelo):\n",
    "    print(\"üîÑ Carregando modelo Word2Vec existente...\")\n",
    "    model = Word2Vec.load(caminho_modelo.replace(\".kv\", \".model\"))\n",
    "else:\n",
    "    print(\"‚öôÔ∏è  Treinando novo modelo Word2Vec...\")\n",
    "    model = Word2Vec(\n",
    "        tokenList,\n",
    "        vector_size=tamanho,\n",
    "        window=janela,\n",
    "        min_count=minimoC,\n",
    "        sg=1,\n",
    "        seed=10\n",
    "    )\n",
    "    # salva o modelo completo (.model) e s√≥ os vetores (.kv)\n",
    "    model.save(caminho_modelo.replace(\".kv\", \".model\"))\n",
    "    model.wv.save(caminho_modelo)\n",
    "    print(\"üíæ Modelo salvo em:\", caminho_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a96d3ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_document_vector(word2vec_model, doc):\n",
    "  doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n",
    "  if doc:\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0)\n",
    "  else:\n",
    "    return np.zeros(word2vec_model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58d64728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43678, 300)\n"
     ]
    }
   ],
   "source": [
    "X_vectors = np.array([\n",
    "    avg_document_vector(model, tokens)\n",
    "    for tokens in tokenList\n",
    "])\n",
    "print(X_vectors.shape)\n",
    "\n",
    "X_vectors_df = pd.DataFrame(X_vectors)\n",
    "X_vectors_df[\"label\"] = df[\"label\"].values\n",
    "\n",
    "tamanho = 300  # garante que est√° como int\n",
    "X_vectors_df.to_csv(f'./data/X_vectors_{tamanho}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8605b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vectors, df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9a3b63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    academic       0.57      0.53      0.55      2919\n",
      "  government       0.62      0.69      0.65      3756\n",
      "     private       0.53      0.46      0.50      2061\n",
      "\n",
      "    accuracy                           0.58      8736\n",
      "   macro avg       0.57      0.56      0.57      8736\n",
      "weighted avg       0.58      0.58      0.58      8736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Faz previs√µes\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Avalia o modelo\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb44264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# y precisa ser num√©rico\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(df[\"label\"])\n",
    "\n",
    "# separa treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vectors, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# converte para tensores\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_t  = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# cria DataLoader\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67ec1fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "input_dim = X_vectors.shape[1]     # 300 (tamanho do embedding)\n",
    "hidden_dim = 1024                   # n√∫mero de neur√¥nios na camada oculta\n",
    "output_dim = len(le.classes_)      # n√∫mero de classes\n",
    "model = TextClassifier(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af3f5951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âpoca 1: perda m√©dia = 0.8481\n",
      "√âpoca 2: perda m√©dia = 0.8413\n",
      "√âpoca 3: perda m√©dia = 0.8374\n",
      "√âpoca 4: perda m√©dia = 0.8330\n",
      "√âpoca 5: perda m√©dia = 0.8291\n",
      "√âpoca 6: perda m√©dia = 0.8240\n",
      "√âpoca 7: perda m√©dia = 0.8192\n",
      "√âpoca 8: perda m√©dia = 0.8179\n",
      "√âpoca 9: perda m√©dia = 0.8119\n",
      "√âpoca 10: perda m√©dia = 0.8096\n",
      "√âpoca 11: perda m√©dia = 0.8048\n",
      "√âpoca 12: perda m√©dia = 0.8043\n",
      "√âpoca 13: perda m√©dia = 0.7985\n",
      "√âpoca 14: perda m√©dia = 0.7967\n",
      "√âpoca 15: perda m√©dia = 0.7952\n",
      "√âpoca 16: perda m√©dia = 0.7922\n",
      "√âpoca 17: perda m√©dia = 0.7892\n",
      "√âpoca 18: perda m√©dia = 0.7845\n",
      "√âpoca 19: perda m√©dia = 0.7823\n",
      "√âpoca 20: perda m√©dia = 0.7804\n",
      "√âpoca 21: perda m√©dia = 0.7755\n",
      "√âpoca 22: perda m√©dia = 0.7746\n",
      "√âpoca 23: perda m√©dia = 0.7697\n",
      "√âpoca 24: perda m√©dia = 0.7693\n",
      "√âpoca 25: perda m√©dia = 0.7659\n",
      "√âpoca 26: perda m√©dia = 0.7624\n",
      "√âpoca 27: perda m√©dia = 0.7621\n",
      "√âpoca 28: perda m√©dia = 0.7624\n",
      "√âpoca 29: perda m√©dia = 0.7599\n",
      "√âpoca 30: perda m√©dia = 0.7551\n",
      "√âpoca 31: perda m√©dia = 0.7536\n",
      "√âpoca 32: perda m√©dia = 0.7507\n",
      "√âpoca 33: perda m√©dia = 0.7480\n",
      "√âpoca 34: perda m√©dia = 0.7477\n",
      "√âpoca 35: perda m√©dia = 0.7444\n",
      "√âpoca 36: perda m√©dia = 0.7444\n",
      "√âpoca 37: perda m√©dia = 0.7384\n",
      "√âpoca 38: perda m√©dia = 0.7395\n",
      "√âpoca 39: perda m√©dia = 0.7339\n",
      "√âpoca 40: perda m√©dia = 0.7324\n",
      "√âpoca 41: perda m√©dia = 0.7319\n",
      "√âpoca 42: perda m√©dia = 0.7301\n",
      "√âpoca 43: perda m√©dia = 0.7311\n",
      "√âpoca 44: perda m√©dia = 0.7257\n",
      "√âpoca 45: perda m√©dia = 0.7212\n",
      "√âpoca 46: perda m√©dia = 0.7218\n",
      "√âpoca 47: perda m√©dia = 0.7191\n",
      "√âpoca 48: perda m√©dia = 0.7170\n",
      "√âpoca 49: perda m√©dia = 0.7207\n",
      "√âpoca 50: perda m√©dia = 0.7142\n",
      "√âpoca 51: perda m√©dia = 0.7134\n",
      "√âpoca 52: perda m√©dia = 0.7099\n",
      "√âpoca 53: perda m√©dia = 0.7087\n",
      "√âpoca 54: perda m√©dia = 0.7064\n",
      "√âpoca 55: perda m√©dia = 0.7065\n",
      "√âpoca 56: perda m√©dia = 0.7039\n",
      "√âpoca 57: perda m√©dia = 0.7045\n",
      "√âpoca 58: perda m√©dia = 0.7014\n",
      "√âpoca 59: perda m√©dia = 0.7030\n",
      "√âpoca 60: perda m√©dia = 0.7011\n",
      "√âpoca 61: perda m√©dia = 0.7020\n",
      "√âpoca 62: perda m√©dia = 0.6928\n",
      "√âpoca 63: perda m√©dia = 0.6920\n",
      "√âpoca 64: perda m√©dia = 0.6916\n",
      "√âpoca 65: perda m√©dia = 0.6913\n",
      "√âpoca 66: perda m√©dia = 0.6924\n",
      "√âpoca 67: perda m√©dia = 0.6862\n",
      "√âpoca 68: perda m√©dia = 0.6905\n",
      "√âpoca 69: perda m√©dia = 0.6843\n",
      "√âpoca 70: perda m√©dia = 0.6852\n",
      "√âpoca 71: perda m√©dia = 0.6808\n",
      "√âpoca 72: perda m√©dia = 0.6804\n",
      "√âpoca 73: perda m√©dia = 0.6799\n",
      "√âpoca 74: perda m√©dia = 0.6794\n",
      "√âpoca 75: perda m√©dia = 0.6776\n",
      "√âpoca 76: perda m√©dia = 0.6772\n",
      "√âpoca 77: perda m√©dia = 0.6727\n",
      "√âpoca 78: perda m√©dia = 0.6729\n",
      "√âpoca 79: perda m√©dia = 0.6726\n",
      "√âpoca 80: perda m√©dia = 0.6712\n",
      "√âpoca 81: perda m√©dia = 0.6683\n",
      "√âpoca 82: perda m√©dia = 0.6698\n",
      "√âpoca 83: perda m√©dia = 0.6671\n",
      "√âpoca 84: perda m√©dia = 0.6698\n",
      "√âpoca 85: perda m√©dia = 0.6610\n",
      "√âpoca 86: perda m√©dia = 0.6582\n",
      "√âpoca 87: perda m√©dia = 0.6614\n",
      "√âpoca 88: perda m√©dia = 0.6636\n",
      "√âpoca 89: perda m√©dia = 0.6606\n",
      "√âpoca 90: perda m√©dia = 0.6540\n",
      "√âpoca 91: perda m√©dia = 0.6600\n",
      "√âpoca 92: perda m√©dia = 0.6555\n",
      "√âpoca 93: perda m√©dia = 0.6530\n",
      "√âpoca 94: perda m√©dia = 0.6499\n",
      "√âpoca 95: perda m√©dia = 0.6511\n",
      "√âpoca 96: perda m√©dia = 0.6507\n",
      "√âpoca 97: perda m√©dia = 0.6511\n",
      "√âpoca 98: perda m√©dia = 0.6486\n",
      "√âpoca 99: perda m√©dia = 0.6477\n",
      "√âpoca 100: perda m√©dia = 0.6430\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"√âpoca {epoch+1}: perda m√©dia = {total_loss/len(train_dl):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aac1a108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia: 64.07%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test_t).argmax(dim=1)\n",
    "    acc = (preds == y_test_t).float().mean().item()\n",
    "    print(f\"Acur√°cia: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a2fac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    academic       0.65      0.63      0.64      2919\n",
      "  government       0.69      0.71      0.70      3756\n",
      "     private       0.54      0.54      0.54      2061\n",
      "\n",
      "    accuracy                           0.64      8736\n",
      "   macro avg       0.63      0.62      0.63      8736\n",
      "weighted avg       0.64      0.64      0.64      8736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds.numpy(), target_names=le.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACH2118-2025-EP2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
